{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(in_text):\n",
    "    \n",
    "    # replace '\\n' with ' '\n",
    "    \n",
    "    # replace . with ' '\n",
    "    in_text = in_text.replace('.', ' ')\n",
    "    \n",
    "    # replace , with ' '\n",
    "    in_text = in_text.replace(',', ' ')\n",
    "    \n",
    "    # replace ' with ' '\n",
    "    in_text = in_text.replace(\"'\", \"\")\n",
    "    \n",
    "    # replace \" with ' '\n",
    "    in_text = in_text.replace('\"', ' ')\n",
    "    \n",
    "    # replace '  ' with ' '\n",
    "    #in_text = in_text.replace('  ', ' ')\n",
    "    \n",
    "    in_text = in_text.replace(\"\\r\",\"\")\n",
    "    in_text = in_text.replace(\"\\n\",\"\")\n",
    "    \n",
    "    # Make the text all upper case - upper()\n",
    "    \n",
    "    return in_text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_WER(Original_text, Transcribed_text):\n",
    "    \n",
    "    # Tokenise the original text into list of words [Orig_lst]\n",
    "    Orig_lst = Original_text.upper().split()\n",
    "    \n",
    "    # Tokenise the transcribed text into list of words [Transcribed_lst/TL]\n",
    "    Transcribed_lst = Transcribed_text.upper().split()\n",
    "    \n",
    "    # List of words for matches: matched_lst\n",
    "    matched_lst = []\n",
    "    \n",
    "    print(\"Type of matched_lst: \" + str(type(matched_lst)))\n",
    "\n",
    "    # List of words for deletions: deleted_lst\n",
    "    deleted_lst = []\n",
    "\n",
    "    # List of words for new insertions: inserted_lst\n",
    "    inserted_lst = []\n",
    "\n",
    "    # For each word in Orig_lst(SL):\n",
    "    for src_word in Orig_lst:\n",
    "\n",
    "        ## If the word is found in TL:        \n",
    "        if src_word in Transcribed_lst:\n",
    "            #print(src_word)\n",
    "            # a) Add the word in match_lst\n",
    "            matched_lst.append(src_word)\n",
    "            #print(\"found!\")\n",
    "        \n",
    "            # b) Remove the word from transcribed_list\n",
    "            Transcribed_lst.remove(src_word)\n",
    "        \n",
    "        else: #(if word is not found in TL)\n",
    "            # a) Add the word in deleted_list\n",
    "            deleted_lst.append(src_word)\n",
    "            #print(\"not found!\")\n",
    "        \n",
    "        \n",
    "    for word in Transcribed_lst:\n",
    "        inserted_lst.append(word)\n",
    "        \n",
    "    return matched_lst, inserted_lst, deleted_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read \"transcription_analysis.csv\"\n",
    "df_transcription = pd.read_csv(\"transcription_analysis.csv\")\n",
    "\n",
    "df_transcription['GCP_match_list_raw'] = df_transcription['GCP_match_list_raw'].astype(object)\n",
    "df_transcription['GCP_insertion_list_raw'] = df_transcription['GCP_insertion_list_raw'].astype(object)\n",
    "df_transcription['GCP_deletion_list_raw'] = df_transcription['GCP_deletion_list_raw'].astype(object)\n",
    "\n",
    "\n",
    "df_transcription['Azure_match_list_raw'] = df_transcription['Azure_match_list_raw'].astype(object)\n",
    "df_transcription['Azure_insertion_list_raw'] = df_transcription['Azure_insertion_list_raw'].astype(object)\n",
    "df_transcription['Azure_deletion_list_raw'] = df_transcription['Azure_deletion_list_raw'].astype(object)\n",
    "\n",
    "\n",
    "df_transcription['LabTwin_match_list_raw'] = df_transcription['LabTwin_match_list_raw'].astype(object)\n",
    "df_transcription['LabTwin_insertion_list_raw'] = df_transcription['LabTwin_insertion_list_raw'].astype(object)\n",
    "df_transcription['LabTwin_deletion_list_raw'] = df_transcription['LabTwin_deletion_list_raw'].astype(object)\n",
    "\n",
    "\n",
    "# for each row in df_transcription\n",
    "for index, row in df_transcription.iterrows():\n",
    "    \n",
    "    print(\"Index: \" + str(index))\n",
    "    \n",
    "    ## Assign Orig_text = row['Human_Transcription']\n",
    "    if (row['Human_Transcription'] == pd.np.nan):\n",
    "        continue\n",
    "        \n",
    "    Orig_text = clean_text(row['Human_Transcription'])\n",
    "      \n",
    "    ## For GCP---------------------------------------------START----\n",
    "    ## Assign transcribed_text = row['Google_Transcription']\n",
    "    transcribed_text = row['Google_Transcription']\n",
    "    transcribed_text = clean_text(transcribed_text)\n",
    "    \n",
    "   # print(type(transcribed_text))\n",
    "\n",
    "    if(len(transcribed_text) <= 0 or len(Orig_text) <= 0):\n",
    "        continue\n",
    "    \n",
    "    ## matched_lst, inserted_lst, deleted_lst = Get_WER(Orig_text, transcribed_text)\n",
    "    matched_lst, inserted_lst, deleted_lst = Get_WER(Orig_text, transcribed_text)\n",
    "    \n",
    "    print(type(matched_lst))\n",
    "    \n",
    "    \n",
    "    print(matched_lst)\n",
    "    \n",
    "    ## Save matched_lst to row['GCP_match_list_raw']    \n",
    "    df_transcription.at[index, 'GCP_match_list_raw'] = matched_lst\n",
    "    \n",
    "    ## save inserted_lst to row['GCP_insertion_list_raw']\n",
    "    df_transcription.at[index, 'GCP_insertion_list_raw'] = inserted_lst\n",
    "    \n",
    "    ## save deleted_lst to row['GCP_deletion_list_raw']\n",
    "    df_transcription.at[index, 'GCP_deletion_list_raw'] = deleted_lst\n",
    "    \n",
    "    ## Add the counts\n",
    "    df_transcription.at[index, 'GCP_match_count_raw'] = len(matched_lst)\n",
    "    df_transcription.at[index, 'GCP_insert_count_raw'] = len(inserted_lst)\n",
    "    df_transcription.at[index, 'GCP_delete_count_raw'] = len(deleted_lst)    \n",
    "    ## For GCP---------------------------------------------END----\n",
    "    \n",
    "    \n",
    "\n",
    "    ## For Azure---------------------------------------------START----\n",
    "    ## Assign transcribed_text = row['Azure_Transcription']\n",
    "    transcribed_text = row['Azure_Transcription']\n",
    "    transcribed_text = clean_text(transcribed_text)\n",
    "    \n",
    "    if(len(transcribed_text) <= 0 or len(Orig_text) <= 0):\n",
    "        continue\n",
    "    \n",
    "    ## matched_lst, inserted_lst, deleted_lst = Get_WER(Orig_text, transcribed_text)     \n",
    "    matched_lst, inserted_lst, deleted_lst = Get_WER(Orig_text, transcribed_text)\n",
    "    \n",
    "    ## Save matched_lst to row['Azure_match_list_raw'] \n",
    "    df_transcription.at[index, 'Azure_match_list_raw'] = matched_lst\n",
    "        \n",
    "    ## save inserted_lst to row['Azure_insertion_list_raw']    \n",
    "    df_transcription.at[index, 'Azure_insertion_list_raw'] = inserted_lst\n",
    "    \n",
    "    ## save deleted_lst to row['Azure_deletion_list_raw']\n",
    "    df_transcription.at[index, 'Azure_deletion_list_raw'] = deleted_lst\n",
    "    \n",
    "    \n",
    "    ## Add the counts\n",
    "    df_transcription.at[index, 'Azure_match_count_raw'] = len(matched_lst)\n",
    "    df_transcription.at[index, 'Azure_insert_count_raw'] = len(inserted_lst)\n",
    "    df_transcription.at[index, 'Azure_delete_count_raw'] = len(deleted_lst)\n",
    "    ## For Azure---------------------------------------------END----\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcription.to_csv(\"matched_transcription_analysis.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
